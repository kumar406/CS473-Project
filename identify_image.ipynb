{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'Tensorflow\\\\workspace\\\\images\\\\test\\\\110.png'\n",
    "CHECKPOINT_PATH = 'Tensorflow\\\\workspace\\\\models\\\\bingus_model\\\\ckpt-4'\n",
    "PIPELINE_CONFIG_PATH = 'Tensorflow\\\\workspace\\\\models\\\\bingus_model\\\\pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(pipeline_config_path, ckpt_path):\n",
    "    # Load pipeline config and build a detection model\n",
    "    configs = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "    detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "    # Restore checkpoint\n",
    "    ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "    ckpt.restore(ckpt_path).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "def label_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    image_np = np.array(img)\n",
    "    y_h = image_np.shape[0]\n",
    "    x_h = image_np.shape[1]\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    # print(detections)\n",
    "    # print(len(detections))\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    final_detections = []\n",
    "    for i in range(detections['num_detections']):\n",
    "        if detections['detection_scores'][i] > THRESHOLD:\n",
    "            dbox = np.copy(detections['detection_boxes'][i])\n",
    "            dbox[0] *= y_h\n",
    "            dbox[1] *= x_h\n",
    "            dbox[2] *= y_h\n",
    "            dbox[3] *= x_h\n",
    "            final_detections.append({\n",
    "                'label': detections['detection_classes'][i] + label_id_offset,\n",
    "                'box_norm': detections['detection_boxes'][i],\n",
    "                'box': dbox.astype(int),\n",
    "                'score': detections['detection_scores'][i]\n",
    "                })\n",
    "    return final_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(CHECKPOINT_PATH).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "y_h = image_np.shape[0]\n",
    "x_h = image_np.shape[1]\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "# print(detections)\n",
    "# print(len(detections))\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_detections = []\n",
    "THRESHOLD = 0.3\n",
    "for i in range(detections['num_detections']):\n",
    "    if detections['detection_scores'][i] > THRESHOLD:\n",
    "        dbox = np.copy(detections['detection_boxes'][i])\n",
    "        dbox[0] *= y_h\n",
    "        dbox[1] *= x_h\n",
    "        dbox[2] *= y_h\n",
    "        dbox[3] *= x_h\n",
    "        final_detections.append({\n",
    "            'label': detections['detection_classes'][i] + label_id_offset,\n",
    "            'box_norm': detections['detection_boxes'][i],\n",
    "            'box': dbox.astype(int),\n",
    "            'score': detections['detection_scores'][i]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 3,\n",
       "  'box_norm': array([0.43824703, 0.41720623, 0.5775799 , 0.5425698 ], dtype=float32),\n",
       "  'box': array([ 773, 1593, 1018, 2072]),\n",
       "  'score': 0.99421114},\n",
       " {'label': 1,\n",
       "  'box_norm': array([0.        , 0.3701775 , 0.36916012, 0.6272964 ], dtype=float32),\n",
       "  'box': array([   0, 1414,  651, 2396]),\n",
       "  'score': 0.9936568},\n",
       " {'label': 3,\n",
       "  'box_norm': array([0.03292408, 0.21814719, 0.16734695, 0.34571692], dtype=float32),\n",
       "  'box': array([  58,  833,  295, 1320]),\n",
       "  'score': 0.99266666},\n",
       " {'label': 3,\n",
       "  'box_norm': array([0.8016169 , 0.39198196, 0.9586301 , 0.5374013 ], dtype=float32),\n",
       "  'box': array([1414, 1497, 1691, 2052]),\n",
       "  'score': 0.9909662},\n",
       " {'label': 1,\n",
       "  'box_norm': array([0.27778032, 0.002736  , 0.790285  , 0.2558999 ], dtype=float32),\n",
       "  'box': array([ 490,   10, 1394,  977]),\n",
       "  'score': 0.989134},\n",
       " {'label': 3,\n",
       "  'box_norm': array([0.03168967, 0.65816694, 0.17212266, 0.7855497 ], dtype=float32),\n",
       "  'box': array([  55, 2514,  303, 3000]),\n",
       "  'score': 0.98225397},\n",
       " {'label': 1,\n",
       "  'box_norm': array([0.3983488, 0.7408758, 0.6080718, 1.       ], dtype=float32),\n",
       "  'box': array([ 702, 2830, 1072, 3820]),\n",
       "  'score': 0.97994417},\n",
       " {'label': 2,\n",
       "  'box_norm': array([0.76961327, 0.6065664 , 0.984624  , 0.8773991 ], dtype=float32),\n",
       "  'box': array([1357, 2317, 1736, 3351]),\n",
       "  'score': 0.9141684},\n",
       " {'label': 1,\n",
       "  'box_norm': array([0.76956284, 0.60632616, 0.983237  , 0.8709249 ], dtype=float32),\n",
       "  'box': array([1357, 2316, 1734, 3326]),\n",
       "  'score': 0.49101233},\n",
       " {'label': 1,\n",
       "  'box_norm': array([0.23741356, 0.        , 0.35724053, 0.25868225], dtype=float32),\n",
       "  'box': array([418,   0, 630, 988]),\n",
       "  'score': 0.39984587},\n",
       " {'label': 1,\n",
       "  'box_norm': array([0.26728418, 0.01075818, 0.38652036, 0.23253429], dtype=float32),\n",
       "  'box': array([471,  41, 681, 888]),\n",
       "  'score': 0.39837214}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "final_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}